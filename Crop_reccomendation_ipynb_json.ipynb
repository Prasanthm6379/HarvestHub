{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded from CSV file\n",
            "Dataset shape: (1000, 5)\n",
            "Dataset columns: ['Soil_Type', 'Nutrition_Value', 'Temperature', 'Humidity', 'Crop']\n",
            "Training set size: 800\n",
            "Testing set size: 200\n",
            "\n",
            "Model Accuracy: 0.72 (72.00%)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Barley       0.91      0.91      0.91        33\n",
            "        Corn       0.63      0.56      0.59        34\n",
            "       Maize       0.59      0.47      0.52        34\n",
            "        Rice       1.00      0.97      0.98        33\n",
            "     Soybean       0.47      0.55      0.51        33\n",
            "       Wheat       0.72      0.88      0.79        33\n",
            "\n",
            "    accuracy                           0.72       200\n",
            "   macro avg       0.72      0.72      0.72       200\n",
            "weighted avg       0.72      0.72      0.72       200\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[30  0  0  0  0  3]\n",
            " [ 0 19  2  0  7  6]\n",
            " [ 0  4 16  0 13  1]\n",
            " [ 0  0  1 32  0  0]\n",
            " [ 0  7  7  0 18  1]\n",
            " [ 3  0  1  0  0 29]]\n",
            "\n",
            "Feature Importance:\n",
            "           feature  importance\n",
            "2         Humidity    0.352960\n",
            "1      Temperature    0.325490\n",
            "0  Nutrition_Value    0.194766\n",
            "4   Soil_Type_Clay    0.033296\n",
            "6   Soil_Type_Sand    0.028303\n",
            "7   Soil_Type_Silt    0.025120\n",
            "5   Soil_Type_Loam    0.020972\n",
            "3  Soil_Type_Chalk    0.019092\n",
            "\n",
            "==================================================\n",
            "CROP PREDICTION FOR NEW INPUT\n",
            "==================================================\n",
            "\n",
            "Predicted Crop: Wheat\n",
            "Prediction Confidence: 0.39 (39.00%)\n",
            "\n",
            "Probabilities for all crops:\n",
            "Barley: 0.150 (15.0%)\n",
            "Corn: 0.090 (9.0%)\n",
            "Maize: 0.180 (18.0%)\n",
            "Rice: 0.160 (16.0%)\n",
            "Soybean: 0.030 (3.0%)\n",
            "Wheat: 0.390 (39.0%)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "data = {\n",
        "    'Soil_Type': ['Clay', 'Loam', 'Silt', 'Sand', 'Pit', 'Chalk'],\n",
        "    'Nutrition_Value': [30, 40, 25, 35, 45, 30],\n",
        "    'Temperature': [25, 28, 20, 30, 22, 28],\n",
        "    'Humidity': [60, 70, 50, 80, 45, 75],\n",
        "    'Crop': ['Wheat', 'Maize', 'Rice', 'Barley', 'Corn', 'Soybean']\n",
        "}\n",
        "\n",
        "# Load dataset\n",
        "try:\n",
        "    df = pd.read_csv('crop_prediction_dataset.csv')\n",
        "    print(\"Dataset loaded from CSV file\")\n",
        "except FileNotFoundError:\n",
        "    print(\"CSV file not found. Using sample dataset.\")\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Dataset columns: {df.columns.tolist()}\")\n",
        "\n",
        "# Convert categorical variables into numerical using one-hot encoding\n",
        "df = pd.get_dummies(df, columns=['Soil_Type'])\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df.drop('Crop', axis=1)\n",
        "y = df['Crop']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Testing set size: {X_test.shape[0]}\")\n",
        "\n",
        "# Create a Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier on training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on test data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.2f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "# Display additional evaluation metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': rf_classifier.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Get feature names (excluding Soil_Type columns)\n",
        "feature_names = [col for col in X.columns if 'Soil_Type' not in col]\n",
        "\n",
        "# Get user input for each feature (including Soil_Type)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CROP PREDICTION FOR NEW INPUT\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "user_input = {}\n",
        "for feature in feature_names:\n",
        "    user_input[feature] = float(input(f\"Enter value for {feature}: \"))\n",
        "\n",
        "# Get user input for Soil_Type separately\n",
        "soil_type_input = input(\"Enter Soil Type (Clay/Loam/Silt/Sand/Pit/Chalk): \")\n",
        "\n",
        "# Create a dataframe with user input\n",
        "user_df = pd.DataFrame([user_input])\n",
        "\n",
        "# Add one-hot encoded Soil_Type columns based on user input\n",
        "for soil_type in ['Clay', 'Loam', 'Silt', 'Sand', 'Pit', 'Chalk']:\n",
        "    user_df[f\"Soil_Type_{soil_type}\"] = 1 if soil_type == soil_type_input else 0\n",
        "\n",
        "# Reorder columns to match the order during training\n",
        "user_df = user_df[X.columns]\n",
        "\n",
        "# Make prediction on user input\n",
        "prediction = rf_classifier.predict(user_df)\n",
        "prediction_proba = rf_classifier.predict_proba(user_df)\n",
        "\n",
        "print(f\"\\nPredicted Crop: {prediction[0]}\")\n",
        "print(f\"Prediction Confidence: {max(prediction_proba[0]):.2f} ({max(prediction_proba[0])*100:.2f}%)\")\n",
        "\n",
        "# Show probability for all classes\n",
        "print(\"\\nProbabilities for all crops:\")\n",
        "for i, crop in enumerate(rf_classifier.classes_):\n",
        "    print(f\"{crop}: {prediction_proba[0][i]:.3f} ({prediction_proba[0][i]*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-25T04:34:26.576765Z",
          "start_time": "2024-04-25T04:34:26.566503Z"
        },
        "id": "AMkv4pWmh43x",
        "outputId": "9ad2cda7-5850-4473-9233-824e060e3707"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Nutrition_Value', 'Temperature', 'Humidity', 'Soil_Type_Chalk',\n",
              "       'Soil_Type_Clay', 'Soil_Type_Loam', 'Soil_Type_Pit', 'Soil_Type_Sand',\n",
              "       'Soil_Type_Silt'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-25T04:34:27.495289Z",
          "start_time": "2024-04-25T04:34:27.429556Z"
        },
        "id": "qfj12C07h43x",
        "outputId": "246516bf-7adf-40a2-b0a8-2ad37beaf806"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['random_forest_model.pkl']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(rf_classifier, 'random_forest_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-25T04:19:48.344600Z",
          "start_time": "2024-04-25T04:19:48.328357Z"
        },
        "id": "oT5JtKQdVHF4"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('model.pkl', 'wb') as file:\n",
        "  pickle.dump(rf_classifier, file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
